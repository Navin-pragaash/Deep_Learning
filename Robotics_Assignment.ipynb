{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOvbEWmKkUQ2ZXZvhp5IVYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navin-pragaash/Deep_Learning/blob/main/Robotics_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the path to your zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/DATASET.zip'  # Change this to the path of your zip file\n",
        "\n",
        "# Step 3: Define the extraction folders for images and text files\n",
        "image_extract_folder = '/content/drive/MyDrive/extracted_images'  # Folder to store extracted images\n",
        "text_extract_folder = '/content/drive/MyDrive/extracted_texts'   # Folder to store extracted text files\n",
        "\n",
        "# Step 4: Create extraction folders if they don't exist\n",
        "os.makedirs(image_extract_folder, exist_ok=True)\n",
        "os.makedirs(text_extract_folder, exist_ok=True)\n",
        "\n",
        "# Step 5: Extract files from the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Iterate through the contents of the zip file\n",
        "    for file_name in zip_ref.namelist():\n",
        "        # Extract image files (common image extensions)\n",
        "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
        "            zip_ref.extract(file_name, image_extract_folder)\n",
        "        # Extract text files (common text file extensions)\n",
        "        elif file_name.lower().endswith(('.txt', '.csv', '.json', '.xml')):\n",
        "            zip_ref.extract(file_name, text_extract_folder)\n",
        "\n",
        "# Step 6: Verify the extraction by listing the files in the extraction directories\n",
        "extracted_images = os.listdir(image_extract_folder)\n",
        "extracted_texts = os.listdir(text_extract_folder)\n",
        "\n",
        "print(f\"Extracted {len(extracted_images)} image(s): {extracted_images[:10]}...\")  # Display first 10 image names\n",
        "print(f\"Extracted {len(extracted_texts)} text file(s): {extracted_texts[:10]}...\")  # Display first 10 text file names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1iRWGqt_DQz",
        "outputId": "a0ef6e21-fdff-42a0-ac33-5f30254223fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted 1 image(s): ['DATASET']...\n",
            "Extracted 1 text file(s): ['DATASET']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function for image preprocessing\n",
        "def preprocess_image(image_path, target_size=(224, 224), convert_grayscale=False):\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    image_resized = cv2.resize(image, target_size)\n",
        "\n",
        "    # Convert to grayscale if needed\n",
        "    if convert_grayscale:\n",
        "        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
        "        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR)  # To keep it 3-channel\n",
        "\n",
        "    # Normalize the image (scale pixel values to [0, 1])\n",
        "    image_normalized = image_resized.astype('float32') / 255.0\n",
        "\n",
        "    return image_normalized\n",
        "\n",
        "# Function for text preprocessing\n",
        "def preprocess_text(text_path):\n",
        "    with open(text_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove non-alphanumeric characters (keep spaces)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    # Tokenization (split text into words)\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Paths for the extracted image and text folders\n",
        "image_extract_folder = '/content/drive/MyDrive/extracted_images'\n",
        "text_extract_folder = '/content/drive/MyDrive/extracted_texts'\n",
        "\n",
        "# Create folders for preprocessed images and text if they don't exist\n",
        "preprocessed_images_folder = '/content/drive/MyDrive/preprocessed_images'\n",
        "preprocessed_texts_folder = '/content/drive/MyDrive/preprocessed_texts'\n",
        "\n",
        "os.makedirs(preprocessed_images_folder, exist_ok=True)\n",
        "os.makedirs(preprocessed_texts_folder, exist_ok=True)\n",
        "\n",
        "# Get the list of image files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGtlMEF6BEjS",
        "outputId": "ca867123-9b2e-4824-ac34-d01dbda2fd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function for image preprocessing\n",
        "def preprocess_image(image_path, target_size=(224, 224), convert_grayscale=False):\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Error: Could not read image {image_path}.\")\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    image_resized = cv2.resize(image, target_size)\n",
        "\n",
        "    # Convert to grayscale if needed\n",
        "    if convert_grayscale:\n",
        "        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
        "        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR)  # To keep it 3-channel\n",
        "\n",
        "    # Normalize the image (scale pixel values to [0, 1])\n",
        "    image_normalized = image_resized.astype('float32') / 255.0\n",
        "\n",
        "    return image_normalized\n",
        "\n",
        "# Function for text preprocessing\n",
        "def preprocess_text(text_path):\n",
        "    with open(text_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove non-alphanumeric characters (keep spaces)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    # Tokenization (split text into words)\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Paths for the extracted image and text folders\n",
        "image_extract_folder = '/content/drive/MyDrive/extracted_images'\n",
        "text_extract_folder = '/content/drive/MyDrive/extracted_texts'\n",
        "\n",
        "# Create folders for preprocessed images and text if they don't exist\n",
        "preprocessed_images_folder = '/content/drive/MyDrive/preprocessed_images'\n",
        "preprocessed_texts_folder = '/content/drive/MyDrive/preprocessed_texts'\n",
        "\n",
        "os.makedirs(preprocessed_images_folder, exist_ok=True)\n",
        "os.makedirs(preprocessed_texts_folder, exist_ok=True)\n",
        "\n",
        "# Get the list of image files\n",
        "image_files = [f for f in os.listdir(image_extract_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n",
        "\n",
        "# Preprocess images and their corresponding text files\n",
        "for image_file in image_files:\n",
        "    # Check if a corresponding text file exists\n",
        "    text_file = os.path.splitext(image_file)[0] + '.txt'\n",
        "    text_path = os.path.join(text_extract_folder, text_file)\n",
        "\n",
        "    if os.path.exists(text_path):\n",
        "        print(f\"Processing {image_file} and {text_file}...\")\n",
        "\n",
        "        # Process the image\n",
        "        image_path = os.path.join(image_extract_folder, image_file)\n",
        "        try:\n",
        "            preprocessed_image = preprocess_image(image_path, target_size=(224, 224), convert_grayscale=False)\n",
        "\n",
        "            # Save the preprocessed image\n",
        "            preprocessed_image_path = os.path.join(preprocessed_images_folder, image_file)\n",
        "            Image.fromarray((preprocessed_image * 255).astype(np.uint8)).save(preprocessed_image_path)\n",
        "\n",
        "            print(f\"Preprocessed image saved at: {preprocessed_image_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_file}: {e}\")\n",
        "\n",
        "        # Process the text file\n",
        "        try:\n",
        "            preprocessed_text = preprocess_text(text_path)\n",
        "\n",
        "            # Save the preprocessed text\n",
        "            preprocessed_text_path = os.path.join(preprocessed_texts_folder, text_file)\n",
        "            with open(preprocessed_text_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(preprocessed_text)\n",
        "\n",
        "            print(f\"Preprocessed text saved at: {preprocessed_text_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing text file {text_file}: {e}\")\n",
        "    else:\n",
        "        print(f\"No corresponding text file for {image_file}. Skipping...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDbk5Cf0Bvq0",
        "outputId": "5219d26f-348a-43ef-f929-090a8a91673a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}